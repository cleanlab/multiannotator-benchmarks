{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264fb0bf",
   "metadata": {},
   "source": [
    "# This notebook runs a train and eval loop on models with improving consensus labels over each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from utils.model_training import train_models\n",
    "from utils.model_training import sum_xval_folds\n",
    "from utils.data_loading import get_annotator_labels\n",
    "from utils.data_loading import drop_and_distribute\n",
    "from utils.data_loading import get_and_save_consensus_labels\n",
    "from utils.data_loading import get_ground_truth_data_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2b53b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cleanlab.multiannotator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcleanlab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiannotator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_consensus_label\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# get c10h_labels from annotator data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# get consensus_labels from \u001b[39;00m\n\u001b[1;32m      5\u001b[0m consensus_labels \u001b[38;5;241m=\u001b[39m get_consensus_label(pd\u001b[38;5;241m.\u001b[39mDataFrame(c10h_labels))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cleanlab.multiannotator'"
     ]
    }
   ],
   "source": [
    "# Get cifar10h dataset and dropout information from it\n",
    "cifar10_infolder = './data/cifar10h/cifar10h-raw.csv' #c10h raw data folder\n",
    "cifar10_outfolder = './benchmark_data/' #c10h raw data folder\n",
    "\n",
    "max_annotations = 5\n",
    "consensus_outfolder = f'./benchmark_data/cifar10_test_consensus_dataset_range_{max_annotations}_0.csv' #output folder for consensus labels\n",
    "\n",
    "c10h_labels, c10h_true_labels, c10h_true_images = get_annotator_labels(infolder)\n",
    "c10h_labels = drop_and_distribute(c10h_labels)\n",
    "\n",
    "# save c10h_results\n",
    "np.save(f\"{cifar10_outfolder}/c10h_labels_range_{max_annotations}\", c10h_labels)\n",
    "np.save(f\"{cifar10_outfolder}/c10h_true_labels_range_{max_annotations}\", c10h_true_labels)\n",
    "\n",
    "# Generate and save consensus labels\n",
    "consensus_labels = get_and_save_consensus_labels(c10h_labels, consensus_outfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load consensus labels and train model on them\n",
    "models = [\"resnet18\",\"swin_base_patch4_window7_224\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through and retrain model on better pred-probs\n",
    "NUM_MODEL_RETRAINS = 3\n",
    "\n",
    "for i in range(NUM_MODEL_RETRAINS):\n",
    "    for model in models:\n",
    "        # Get folders\n",
    "        if i > 0:\n",
    "            consensus_infolder = consensus_outfolder\n",
    "        else:\n",
    "            consensus_infolder = f'./benchmark_data/cifar10_test_consensus_dataset_range_{max_annotations}_{i}_{model}.csv'\n",
    "        consensus_oufolder = f'./benchmark_data/cifar10_test_consensus_dataset_range_{max_annotations}_{i+1}_{model}.csv'\n",
    "        model_results_folder = f'./data/cifar10_consensus_range_{max_annotations}_{i}' # + [model_type]\n",
    "\n",
    "        # Match label idxs to model\n",
    "        c10h_labels, c10h_true_labels, pred_probs = get_ground_truth_data_matched(f\"{model_results_folder}_{model}\", cifar10_outfolder)\n",
    "        train_models([model], consensus_infolder, model_results_folder)\n",
    "        pred_probs, labels , true_labels, images, results_list = sum_xval_folds([model], model_results_folder)\n",
    "        \n",
    "        # Report basic results\n",
    "        for result in results_list:\n",
    "            print(result)\n",
    "\n",
    "        # Generate and save consensus labels\n",
    "        consensus_labels = get_and_save_consensus_labels(c10h_labels, consensus_outfolder, pred_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
