{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861406e6",
   "metadata": {},
   "source": [
    "# This notebook trains a model with cross-val on the entire dataset\n",
    "- and gets it's pred_probs and saves results as numpy files\n",
    "- make sure we run entirety of evaluate benchmarks to get consensus labeling first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd34358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from autogluon.vision import ImagePredictor, ImageDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import cleanlab\n",
    "from utils.cross_validation_autogluon import cross_val_predict_autogluon_image_dataset\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79617b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/uly/Documents/Cleanlab/h_cleanlab/multiannotator_benchmarks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52251f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  image\n",
       "0      0     15\n",
       "1      1     15\n",
       "2      2     15\n",
       "3      3     15\n",
       "4      4     15\n",
       "5      5     15\n",
       "6      6     15\n",
       "7      7     15\n",
       "8      8     15\n",
       "9      9     15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test files\n",
    "data_filepath = './data/model_data_070622/cifar10_test_consensus_dataset.csv'\n",
    "df = pd.read_csv(data_filepath)\n",
    "\n",
    "# Create mini train dataset\n",
    "num_from_each_group = 15\n",
    "mini_df = df.groupby(\"label\").head(num_from_each_group)\n",
    "mini_df.groupby(\"label\")[\"image\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data path\n",
    "# CIFAR_10_DATA_PATH = \"/Data/cifar10_png/\"\n",
    "\n",
    "# # read data from root folder\n",
    "# train_dataset, _, test_dataset = \\\n",
    "#     ImageDataset.from_folders(\n",
    "#         root=CIFAR_10_DATA_PATH,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e793c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Running cross-validation for model: resnet18\n",
      "----\n",
      "Running Cross-Validation on Split: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Insufficient detected # gpus 0 vs requested 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Cleanlab/h_cleanlab/multiannotator_benchmarks/utils/cross_validation_autogluon.py:73\u001b[0m, in \u001b[0;36mcross_val_predict_autogluon_image_dataset\u001b[0;34m(dataset, out_folder, n_splits, model_params, ngpus_per_trial, time_limit, random_state)\u001b[0m\n\u001b[1;32m     70\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImagePredictor(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# train model on train indices in this split\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngpus_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngpus_per_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# predict on test indices in this split\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# predicted probabilities for test split\u001b[39;00m\n\u001b[1;32m     84\u001b[0m pred_probs \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict_proba(\n\u001b[1;32m     85\u001b[0m     data\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39miloc[test_index], as_pandas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     86\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleanlab-p38/lib/python3.8/site-packages/autogluon/vision/configs/presets_configs.py:18\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     17\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m set_presets(preset_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleanlab-p38/lib/python3.8/site-packages/autogluon/vision/predictor/predictor.py:246\u001b[0m, in \u001b[0;36mImagePredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m         logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImagePredictor sets accuracy as default eval_metric for classification problems.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# init/validate kwargs\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# unpack\u001b[39;00m\n\u001b[1;32m    248\u001b[0m num_trials \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameter_tune_kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_trials\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleanlab-p38/lib/python3.8/site-packages/autogluon/vision/predictor/predictor.py:500\u001b[0m, in \u001b[0;36mImagePredictor._validate_kwargs\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m     detected_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_num_gpus_available()\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detected_gpu \u001b[38;5;241m<\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngpus_per_trial\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient detected # gpus \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetected_gpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs requested \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngpus_per_trial\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# tune kwargs\u001b[39;00m\n\u001b[1;32m    502\u001b[0m hpo_tune_args \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameter_tune_kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient detected # gpus 0 vs requested 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# generate cross-validated predicted probabilities for various models so we can use them for ensemble scoring methods\n",
    "models = [\n",
    "    \"resnet18\",\n",
    "    \"swin_base_patch4_window7_224\"\n",
    "]\n",
    "\n",
    "epochs = 1\n",
    "holdout_frac = 0.2\n",
    "n_splits = 5\n",
    "\n",
    "# run cross-validation for each model\n",
    "for model in models:\n",
    "    \n",
    "    print(\"----\")\n",
    "    print(f\"Running cross-validation for model: {model}\")\n",
    "\n",
    "    MODEL_PARAMS = {\n",
    "        \"model\": model,\n",
    "        \"epochs\": epochs,\n",
    "        \"holdout_frac\": holdout_frac,\n",
    "    }\n",
    "\n",
    "    # results of cross-validation will be saved to pickle files for each model/fold\n",
    "    _ = \\\n",
    "        cross_val_predict_autogluon_image_dataset(\n",
    "            dataset=mini_df,\n",
    "            out_folder=f\"./data/cifar10_test_dataset_{model}/\", # save results of cross-validation in pickle files for each fold\n",
    "            n_splits=n_splits,\n",
    "            model_params=MODEL_PARAMS,\n",
    "            time_limit=600,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc171378",
   "metadata": {},
   "source": [
    "## Read pickle files from cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23da39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(pickle_file_name):\n",
    "    \"\"\"Load pickle file\"\"\"\n",
    "\n",
    "    print(f\"Loading {pickle_file_name}\")\n",
    "\n",
    "    with open(pickle_file_name, 'rb') as handle:\n",
    "        out = pickle.load(handle)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79379668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test file read\n",
    "for model in models:\n",
    "    out_subfolder = f\"./data/cifar10_test_dataset_{model}/split_0/\"\n",
    "    split_num = 0\n",
    "\n",
    "    get_pickle_file_name = (\n",
    "        lambda object_name: f\"{out_subfolder}_{object_name}_split_{split_num}\"\n",
    "    )\n",
    "\n",
    "    pred_probs = load_pickle(get_pickle_file_name(\"test_pred_probs\"))\n",
    "    pred_features = load_pickle(get_pickle_file_name(\"test_pred_features\"))\n",
    "    labels = load_pickle(get_pickle_file_name(\"test_labels\"))\n",
    "    images = load_pickle(get_pickle_file_name(\"test_image_files\"))\n",
    "    indices = load_pickle(get_pickle_file_name(\"test_indices\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
